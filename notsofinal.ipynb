{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, applications\n",
    "from ultralytics import YOLO\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "# --------------------------\n",
    "# 1. ENHANCED DATA LOADER\n",
    "# --------------------------\n",
    "class KITTILoader:\n",
    "    def __init__(self, base_path: str):\n",
    "        self.base_path = base_path\n",
    "        self.class_map = {\"Car\": 0, \"Pedestrian\": 1, \"Cyclist\": 2}\n",
    "        self._validate_paths()\n",
    "\n",
    "    def _validate_paths(self):\n",
    "        \"\"\"Verify critical dataset folders exist\"\"\"\n",
    "        required_folders = [\n",
    "            \"data_object_image_2/training/image_2\",\n",
    "            \"data_object_image_3/training/image_3\",\n",
    "            \"data_object_label_2/training/label_2\"\n",
    "        ]\n",
    "        for folder in required_folders:\n",
    "            if not os.path.exists(os.path.join(self.base_path, folder)):\n",
    "                raise FileNotFoundError(f\"‚ùå Missing required folder: {folder}\")\n",
    "\n",
    "    def load_stereo_pair(self, split: str, idx: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Loads and preprocesses stereo image pairs\"\"\"\n",
    "        img_paths = [\n",
    "            os.path.join(self.base_path, f\"data_object_image_2/{split}/image_2/{idx:06d}.png\"),\n",
    "            os.path.join(self.base_path, f\"data_object_image_3/{split}/image_3/{idx:06d}.png\")\n",
    "        ]\n",
    "        \n",
    "        imgs = []\n",
    "        for path in img_paths:\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"‚ùå Image not found: {path}\")\n",
    "            \n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            img = cv2.resize(img, (416, 416))\n",
    "            imgs.append(img)\n",
    "            \n",
    "        return tuple(imgs)\n",
    "\n",
    "    def load_labels(self, split: str, idx: int) -> List[Dict]:\n",
    "        \"\"\"Loads and converts labels to COCO format with enhanced validation\"\"\"\n",
    "        label_path = os.path.join(self.base_path, f\"data_object_label_2/{split}/label_2/{idx:06d}.txt\")\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            return []  # Return empty list if no labels exist\n",
    "\n",
    "        labels = []\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 15:  # Minimum fields in KITTI label\n",
    "                    continue\n",
    "                    \n",
    "                if parts[0] in self.class_map:\n",
    "                    try:\n",
    "                        x1, y1, x2, y2 = map(float, parts[4:8])\n",
    "                        labels.append({\n",
    "                            \"class\": self.class_map[parts[0]],\n",
    "                            \"bbox\": [x1, y1, x2 - x1, y2 - y1],  # COCO format\n",
    "                            \"truncated\": float(parts[1]),\n",
    "                            \"occluded\": int(parts[2])\n",
    "                        })\n",
    "                    except (ValueError, IndexError) as e:\n",
    "                        print(f\"‚ö†Ô∏è Error parsing label {label_path}: {e}\")\n",
    "                        \n",
    "        return labels\n",
    "\n",
    "    def load_calibration(self, split: str, idx: int) -> Optional[Dict]:\n",
    "        \"\"\"Loads calibration data with error handling\"\"\"\n",
    "        calib_path = os.path.join(self.base_path, f\"data_object_calib/{split}/calib/{idx:06d}.txt\")\n",
    "        \n",
    "        if not os.path.exists(calib_path):\n",
    "            print(f\"‚ö†Ô∏è Calibration file not found: {calib_path}\")\n",
    "            return None\n",
    "\n",
    "        calib = {}\n",
    "        with open(calib_path, 'r') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    key, *values = line.strip().split(' ', 1)\n",
    "                    calib[key] = np.array([float(x) for x in values[0].split()]).reshape(3, 4)\n",
    "                except (ValueError, IndexError) as e:\n",
    "                    print(f\"‚ö†Ô∏è Error parsing calibration {calib_path}: {e}\")\n",
    "                    \n",
    "        return calib\n",
    "\n",
    "# --------------------------\n",
    "# 2. IMPROVED SIAMESE NETWORK\n",
    "# --------------------------\n",
    "class StereoVerifier:\n",
    "    def __init__(self, input_shape=(416, 416, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._build_enhanced_model()\n",
    "        \n",
    "    def _build_enhanced_model(self) -> Model:\n",
    "        \"\"\"Enhanced Siamese network with feature normalization\"\"\"\n",
    "        base_cnn = applications.ResNet50(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=self.input_shape\n",
    "        )\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for layer in base_cnn.layers[:100]:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        # Feature normalization\n",
    "        global_average = layers.GlobalAveragePooling2D()\n",
    "        normalization = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "        \n",
    "        # Twin networks\n",
    "        input_left = layers.Input(self.input_shape)\n",
    "        input_right = layers.Input(self.input_shape)\n",
    "        \n",
    "        features_left = normalization(global_average(base_cnn(input_left)))\n",
    "        features_right = normalization(global_average(base_cnn(input_right))))\n",
    "        \n",
    "        # Distance metric\n",
    "        distance = layers.Lambda(\n",
    "            lambda x: tf.reduce_sum(tf.square(x[0] - x[1]), axis=1, keepdims=True)\n",
    "        )([features_left, features_right])\n",
    "        \n",
    "        # Verification head\n",
    "        output = layers.Dense(1, activation='sigmoid')(distance)\n",
    "        \n",
    "        return Model(inputs=[input_left, input_right], outputs=output)\n",
    "\n",
    "    def train(self, loader: KITTILoader, epochs=10, batch_size=32):\n",
    "        \"\"\"Enhanced training with validation split\"\"\"\n",
    "        # Generate balanced pairs\n",
    "        pairs, labels = [], []\n",
    "        sample_count = min(200, len(os.listdir(os.path.join(loader.base_path, \"data_object_image_2/training/image_2\")))\n",
    "        \n",
    "        for i in range(sample_count):\n",
    "            try:\n",
    "                left, right = loader.load_stereo_pair(\"training\", i)\n",
    "                pairs.append([left, right])\n",
    "                labels.append(1)  # Positive pair\n",
    "                \n",
    "                # Negative pair (different stereo pair)\n",
    "                if i > 0:\n",
    "                    _, neg_right = loader.load_stereo_pair(\"training\", i-1)\n",
    "                    pairs.append([left, neg_right])\n",
    "                    labels.append(0)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error loading sample {i}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        # Convert to numpy arrays\n",
    "        left_imgs = np.array([p[0] for p in pairs])\n",
    "        right_imgs = np.array([p[1] for p in pairs])\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Add early stopping\n",
    "        callback = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            [left_imgs, right_imgs],\n",
    "            labels,\n",
    "            validation_split=0.2,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[callback]\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "\n",
    "# --------------------------\n",
    "# 3. ADVANCED STEREO GAN\n",
    "# --------------------------\n",
    "class StereoGAN:\n",
    "    def __init__(self, latent_dim=100, img_shape=(416, 416, 3)):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = img_shape\n",
    "        self.generator = self._build_generator()\n",
    "        self.discriminator = self._build_discriminator()\n",
    "        self.gan = self._build_combined()\n",
    "        \n",
    "    def _build_generator(self) -> Model:\n",
    "        \"\"\"Generator with skip connections\"\"\"\n",
    "        noise = layers.Input(shape=(self.latent_dim,))\n",
    "        \n",
    "        # Shared encoder\n",
    "        x = layers.Dense(512)(noise)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Left image decoder\n",
    "        left = layers.Dense(256)(x)\n",
    "        left = layers.LeakyReLU(0.2)(left)\n",
    "        left = layers.Dense(np.prod(self.img_shape), activation='tanh')(left)\n",
    "        left = layers.Reshape(self.img_shape)(left)\n",
    "        \n",
    "        # Right image decoder with disparity\n",
    "        right = layers.Dense(256)(x)\n",
    "        right = layers.LeakyReLU(0.2)(right)\n",
    "        right = layers.Dense(np.prod(self.img_shape), activation='tanh')(right)\n",
    "        right = layers.Reshape(self.img_shape)(right)\n",
    "        \n",
    "        return Model(noise, [left, right])\n",
    "\n",
    "    def _build_discriminator(self) -> Model:\n",
    "        \"\"\"Discriminator with dual input for stereo pairs\"\"\"\n",
    "        left_input = layers.Input(self.img_shape)\n",
    "        right_input = layers.Input(self.img_shape)\n",
    "        \n",
    "        # Shared feature extractor\n",
    "        def create_feature_extractor():\n",
    "            model = tf.keras.Sequential([\n",
    "                layers.Conv2D(64, (4,4), strides=2, padding='same'),\n",
    "                layers.LeakyReLU(0.2),\n",
    "                layers.Conv2D(128, (4,4), strides=2, padding='same'),\n",
    "                layers.LeakyReLU(0.2),\n",
    "                layers.GlobalMaxPooling2D()\n",
    "            ])\n",
    "            return model\n",
    "            \n",
    "        left_features = create_feature_extractor()(left_input)\n",
    "        right_features = create_feature_extractor()(right_input)\n",
    "        \n",
    "        # Combine features\n",
    "        merged = layers.Concatenate()([left_features, right_features])\n",
    "        validity = layers.Dense(1, activation='sigmoid')(merged)\n",
    "        \n",
    "        return Model([left_input, right_input], validity)\n",
    "\n",
    "    def _build_combined(self) -> Model:\n",
    "        \"\"\"Combined GAN model\"\"\"\n",
    "        self.discriminator.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),\n",
    "            loss='binary_crossentropy'\n",
    "        )\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        noise = layers.Input(shape=(self.latent_dim,))\n",
    "        img_left, img_right = self.generator(noise)\n",
    "        valid = self.discriminator([img_left, img_right])\n",
    "        \n",
    "        return Model(noise, valid)\n",
    "\n",
    "    def train(self, real_left: np.ndarray, real_right: np.ndarray, epochs=100, batch_size=32):\n",
    "        \"\"\"Enhanced GAN training with gradient penalty\"\"\"\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            idx = np.random.randint(0, real_left.shape[0], batch_size)\n",
    "            real_imgs_left = real_left[idx]\n",
    "            real_imgs_right = real_right[idx]\n",
    "            \n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            fake_left, fake_right = self.generator.predict(noise, verbose=0)\n",
    "            \n",
    "            # Train on real and fake images\n",
    "            d_loss_real = self.discriminator.train_on_batch(\n",
    "                [real_imgs_left, real_imgs_right], valid\n",
    "            )\n",
    "            d_loss_fake = self.discriminator.train_on_batch(\n",
    "                [fake_left, fake_right], fake\n",
    "            )\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # ---------------------\n",
    "            # Train Generator\n",
    "            # ---------------------\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            g_loss = self.gan.train_on_batch(noise, valid)\n",
    "            \n",
    "            # Print progress\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch} [D loss: {d_loss[0]} | G loss: {g_loss}]\")\n",
    "\n",
    "# --------------------------\n",
    "# 4. ENHANCED YOLO DETECTOR\n",
    "# --------------------------\n",
    "class KITTIDetector:\n",
    "    def __init__(self, model_type='yolov8n.pt'):\n",
    "        self.model = YOLO(model_type)\n",
    "        self.class_map = {0: 'Car', 1: 'Pedestrian', 2: 'Cyclist'}\n",
    "        \n",
    "    def train(self, data_yaml='kitti.yaml', epochs=50, imgsz=416):\n",
    "        \"\"\"Enhanced training with validation\"\"\"\n",
    "        results = self.model.train(\n",
    "            data=data_yaml,\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            batch=16,\n",
    "            patience=10,  # Early stopping\n",
    "            augment=True,  # Mosaic augmentation\n",
    "            cache=True    # Cache images for faster training\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    def detect_stereo(self, left_img: np.ndarray, right_img: np.ndarray) -> Tuple[np.ndarray, list]:\n",
    "        \"\"\"Enhanced stereo detection with NMS\"\"\"\n",
    "        # Run detection on both images\n",
    "        left_results = self.model(left_img, verbose=False)[0]\n",
    "        right_results = self.model(right_img, verbose=False)[0]\n",
    "        \n",
    "        # Process detections\n",
    "        def process_detections(results):\n",
    "            boxes = []\n",
    "            for box in results.boxes:\n",
    "                if box.conf > 0.5:  # Confidence threshold\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                    class_id = int(box.cls)\n",
    "                    boxes.append({\n",
    "                        'bbox': [x1, y1, x2, y2],\n",
    "                        'class': self.class_map.get(class_id, 'Unknown'),\n",
    "                        'confidence': float(box.conf)\n",
    "                    })\n",
    "            return boxes\n",
    "            \n",
    "        left_detections = process_detections(left_results)\n",
    "        right_detections = process_detections(right_results)\n",
    "        \n",
    "        # Visualize on left image\n",
    "        output_img = left_img.copy()\n",
    "        for det in left_detections + right_detections:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            cv2.rectangle(output_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(\n",
    "                output_img,\n",
    "                f\"{det['class']} {det['confidence']:.2f}\",\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                1\n",
    "            )\n",
    "            \n",
    "        return output_img, left_detections + right_detections\n",
    "\n",
    "# --------------------------\n",
    "# MAIN EXECUTION\n",
    "# --------------------------\n",
    "def main():\n",
    "    # Initialize components\n",
    "    loader = KITTILoader(\"D:/kitti_dataset\")\n",
    "    verifier = StereoVerifier()\n",
    "    detector = KITTIDetector()\n",
    "    \n",
    "    try:\n",
    "        # 1. Load sample data\n",
    "        print(\"üîç Loading sample data...\")\n",
    "        left_img, right_img = loader.load_stereo_pair(\"training\", 0)\n",
    "        labels = loader.load_labels(\"training\", 0)\n",
    "        print(f\"‚úÖ Loaded sample with {len(labels)} objects\")\n",
    "        \n",
    "        # 2. Train Siamese Network\n",
    "        print(\"\\nüéØ Training Siamese Network...\")\n",
    "        verifier.train(loader, epochs=15)\n",
    "        \n",
    "        # 3. Train Object Detector\n",
    "        print(\"\\nüéØ Training YOLOv8 Detector...\")\n",
    "        detector.train(epochs=50)\n",
    "        \n",
    "        # 4. Run Detection\n",
    "        print(\"\\nüîç Running Stereo Detection...\")\n",
    "        test_left, test_right = loader.load_stereo_pair(\"testing\", 0)\n",
    "        result_img, detections = detector.detect_stereo(test_left, test_right)\n",
    "        \n",
    "        # Display results\n",
    "        cv2.imshow(\"Stereo Detections\", cv2.cvtColor(result_img, cv2.COLOR_RGB2BGR))\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        print(f\"\\nüéâ Detected {len(detections)} objects in stereo pair\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in pipeline: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
